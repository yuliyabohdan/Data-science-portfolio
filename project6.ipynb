{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отток клиентов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.\n",
    "\n",
    "Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. \n",
    "\n",
    "Постройте модель с предельно большим значением *F1*-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте *F1*-меру на тестовой выборке самостоятельно.\n",
    "\n",
    "Дополнительно измеряйте *AUC-ROC*, сравнивайте её значение с *F1*-мерой.\n",
    "\n",
    "Источник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = pd.read_csv('/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Признаки\n",
    "    RowNumber — индекс строки в данных\n",
    "    CustomerId — уникальный идентификатор клиента\n",
    "    Surname — фамилия\n",
    "    CreditScore — кредитный рейтинг\n",
    "    Geography — страна проживания\n",
    "    Gender — пол\n",
    "    Age — возраст\n",
    "    Tenure — количество недвижимости у клиента\n",
    "    Balance — баланс на счёте\n",
    "    NumOfProducts — количество продуктов банка, используемых клиентом\n",
    "    HasCrCard — наличие кредитной карты\n",
    "    IsActiveMember — активность клиента\n",
    "    EstimatedSalary — предполагаемая зарплата\n",
    "# Целевой признак\n",
    "    Exited — факт ухода клиента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             9091 non-null float64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "clients.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>15574012</td>\n",
       "      <td>Chu</td>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8.0</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>15592531</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>15656148</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>15792365</td>\n",
       "      <td>He</td>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4.0</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>15592389</td>\n",
       "      <td>H?</td>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>15767821</td>\n",
       "      <td>Bearce</td>\n",
       "      <td>528</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>31</td>\n",
       "      <td>6.0</td>\n",
       "      <td>102016.72</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80181.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>15737173</td>\n",
       "      <td>Andrews</td>\n",
       "      <td>497</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76390.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>15632264</td>\n",
       "      <td>Kay</td>\n",
       "      <td>476</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>34</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26260.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15691483</td>\n",
       "      <td>Chin</td>\n",
       "      <td>549</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>190857.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>15600882</td>\n",
       "      <td>Scott</td>\n",
       "      <td>635</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>35</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65951.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>15643966</td>\n",
       "      <td>Goforth</td>\n",
       "      <td>616</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>143129.41</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64327.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>15737452</td>\n",
       "      <td>Romeo</td>\n",
       "      <td>653</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>132602.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5097.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>15788218</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>549</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14406.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>15661507</td>\n",
       "      <td>Muldrow</td>\n",
       "      <td>587</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>158684.81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>15568982</td>\n",
       "      <td>Hao</td>\n",
       "      <td>726</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54724.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>15577657</td>\n",
       "      <td>McDonald</td>\n",
       "      <td>732</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>170886.17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>15597945</td>\n",
       "      <td>Dellucci</td>\n",
       "      <td>636</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>32</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>138555.46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>15699309</td>\n",
       "      <td>Gerasimov</td>\n",
       "      <td>510</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>118913.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>15725737</td>\n",
       "      <td>Mosman</td>\n",
       "      <td>669</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8487.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>15625047</td>\n",
       "      <td>Yen</td>\n",
       "      <td>846</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>38</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>187616.16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>15738191</td>\n",
       "      <td>Maclean</td>\n",
       "      <td>577</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>25</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>124508.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>15736816</td>\n",
       "      <td>Young</td>\n",
       "      <td>756</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>136815.64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>170041.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>15700772</td>\n",
       "      <td>Nebechi</td>\n",
       "      <td>571</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38433.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>15728693</td>\n",
       "      <td>McWilliams</td>\n",
       "      <td>574</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>3.0</td>\n",
       "      <td>141349.43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>100187.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>15656300</td>\n",
       "      <td>Lucciano</td>\n",
       "      <td>411</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59697.17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>53483.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>15589475</td>\n",
       "      <td>Azikiwe</td>\n",
       "      <td>591</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140469.38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>15706552</td>\n",
       "      <td>Odinakachukwu</td>\n",
       "      <td>533</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>7.0</td>\n",
       "      <td>85311.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>156731.91</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>15750181</td>\n",
       "      <td>Sanderson</td>\n",
       "      <td>553</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>9.0</td>\n",
       "      <td>110112.54</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81898.81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>15659428</td>\n",
       "      <td>Maggard</td>\n",
       "      <td>520</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>34410.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "      <td>15732963</td>\n",
       "      <td>Clements</td>\n",
       "      <td>722</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>142033.07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>15794171</td>\n",
       "      <td>Lombardo</td>\n",
       "      <td>475</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134264.04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27822.99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "      <td>15788448</td>\n",
       "      <td>Watson</td>\n",
       "      <td>490</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>145260.23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>114066.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>15729599</td>\n",
       "      <td>Lorenzo</td>\n",
       "      <td>804</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>33</td>\n",
       "      <td>7.0</td>\n",
       "      <td>76548.60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>98453.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>15717426</td>\n",
       "      <td>Armstrong</td>\n",
       "      <td>850</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40812.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>15585768</td>\n",
       "      <td>Cameron</td>\n",
       "      <td>582</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>6.0</td>\n",
       "      <td>70349.48</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178074.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    RowNumber  CustomerId        Surname  CreditScore Geography  Gender  Age  \\\n",
       "0           1    15634602       Hargrave          619    France  Female   42   \n",
       "1           2    15647311           Hill          608     Spain  Female   41   \n",
       "2           3    15619304           Onio          502    France  Female   42   \n",
       "3           4    15701354           Boni          699    France  Female   39   \n",
       "4           5    15737888       Mitchell          850     Spain  Female   43   \n",
       "5           6    15574012            Chu          645     Spain    Male   44   \n",
       "6           7    15592531       Bartlett          822    France    Male   50   \n",
       "7           8    15656148         Obinna          376   Germany  Female   29   \n",
       "8           9    15792365             He          501    France    Male   44   \n",
       "9          10    15592389             H?          684    France    Male   27   \n",
       "10         11    15767821         Bearce          528    France    Male   31   \n",
       "11         12    15737173        Andrews          497     Spain    Male   24   \n",
       "12         13    15632264            Kay          476    France  Female   34   \n",
       "13         14    15691483           Chin          549    France  Female   25   \n",
       "14         15    15600882          Scott          635     Spain  Female   35   \n",
       "15         16    15643966        Goforth          616   Germany    Male   45   \n",
       "16         17    15737452          Romeo          653   Germany    Male   58   \n",
       "17         18    15788218      Henderson          549     Spain  Female   24   \n",
       "18         19    15661507        Muldrow          587     Spain    Male   45   \n",
       "19         20    15568982            Hao          726    France  Female   24   \n",
       "20         21    15577657       McDonald          732    France    Male   41   \n",
       "21         22    15597945       Dellucci          636     Spain  Female   32   \n",
       "22         23    15699309      Gerasimov          510     Spain  Female   38   \n",
       "23         24    15725737         Mosman          669    France    Male   46   \n",
       "24         25    15625047            Yen          846    France  Female   38   \n",
       "25         26    15738191        Maclean          577    France    Male   25   \n",
       "26         27    15736816          Young          756   Germany    Male   36   \n",
       "27         28    15700772        Nebechi          571    France    Male   44   \n",
       "28         29    15728693     McWilliams          574   Germany  Female   43   \n",
       "29         30    15656300       Lucciano          411    France    Male   29   \n",
       "30         31    15589475        Azikiwe          591     Spain  Female   39   \n",
       "31         32    15706552  Odinakachukwu          533    France    Male   36   \n",
       "32         33    15750181      Sanderson          553   Germany    Male   41   \n",
       "33         34    15659428        Maggard          520     Spain  Female   42   \n",
       "34         35    15732963       Clements          722     Spain  Female   29   \n",
       "35         36    15794171       Lombardo          475    France  Female   45   \n",
       "36         37    15788448         Watson          490     Spain    Male   31   \n",
       "37         38    15729599        Lorenzo          804     Spain    Male   33   \n",
       "38         39    15717426      Armstrong          850    France    Male   36   \n",
       "39         40    15585768        Cameron          582   Germany    Male   41   \n",
       "\n",
       "    Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0      2.0       0.00              1          1               1   \n",
       "1      1.0   83807.86              1          0               1   \n",
       "2      8.0  159660.80              3          1               0   \n",
       "3      1.0       0.00              2          0               0   \n",
       "4      2.0  125510.82              1          1               1   \n",
       "5      8.0  113755.78              2          1               0   \n",
       "6      7.0       0.00              2          1               1   \n",
       "7      4.0  115046.74              4          1               0   \n",
       "8      4.0  142051.07              2          0               1   \n",
       "9      2.0  134603.88              1          1               1   \n",
       "10     6.0  102016.72              2          0               0   \n",
       "11     3.0       0.00              2          1               0   \n",
       "12    10.0       0.00              2          1               0   \n",
       "13     5.0       0.00              2          0               0   \n",
       "14     7.0       0.00              2          1               1   \n",
       "15     3.0  143129.41              2          0               1   \n",
       "16     1.0  132602.88              1          1               0   \n",
       "17     9.0       0.00              2          1               1   \n",
       "18     6.0       0.00              1          0               0   \n",
       "19     6.0       0.00              2          1               1   \n",
       "20     8.0       0.00              2          1               1   \n",
       "21     8.0       0.00              2          1               0   \n",
       "22     4.0       0.00              1          1               0   \n",
       "23     3.0       0.00              2          0               1   \n",
       "24     5.0       0.00              1          1               1   \n",
       "25     3.0       0.00              2          0               1   \n",
       "26     2.0  136815.64              1          1               1   \n",
       "27     9.0       0.00              2          0               0   \n",
       "28     3.0  141349.43              1          1               1   \n",
       "29     0.0   59697.17              2          1               1   \n",
       "30     NaN       0.00              3          1               0   \n",
       "31     7.0   85311.70              1          0               1   \n",
       "32     9.0  110112.54              2          0               0   \n",
       "33     6.0       0.00              2          1               1   \n",
       "34     9.0       0.00              2          1               1   \n",
       "35     0.0  134264.04              1          1               0   \n",
       "36     3.0  145260.23              1          0               1   \n",
       "37     7.0   76548.60              1          0               1   \n",
       "38     7.0       0.00              1          1               1   \n",
       "39     6.0   70349.48              2          0               1   \n",
       "\n",
       "    EstimatedSalary  Exited  \n",
       "0         101348.88       1  \n",
       "1         112542.58       0  \n",
       "2         113931.57       1  \n",
       "3          93826.63       0  \n",
       "4          79084.10       0  \n",
       "5         149756.71       1  \n",
       "6          10062.80       0  \n",
       "7         119346.88       1  \n",
       "8          74940.50       0  \n",
       "9          71725.73       0  \n",
       "10         80181.12       0  \n",
       "11         76390.01       0  \n",
       "12         26260.98       0  \n",
       "13        190857.79       0  \n",
       "14         65951.65       0  \n",
       "15         64327.26       0  \n",
       "16          5097.67       1  \n",
       "17         14406.41       0  \n",
       "18        158684.81       0  \n",
       "19         54724.03       0  \n",
       "20        170886.17       0  \n",
       "21        138555.46       0  \n",
       "22        118913.53       1  \n",
       "23          8487.75       0  \n",
       "24        187616.16       0  \n",
       "25        124508.29       0  \n",
       "26        170041.95       0  \n",
       "27         38433.35       0  \n",
       "28        100187.43       0  \n",
       "29         53483.21       0  \n",
       "30        140469.38       1  \n",
       "31        156731.91       0  \n",
       "32         81898.81       0  \n",
       "33         34410.55       0  \n",
       "34        142033.07       0  \n",
       "35         27822.99       1  \n",
       "36        114066.77       0  \n",
       "37         98453.45       0  \n",
       "38         40812.90       0  \n",
       "39        178074.04       0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients.head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим около 900 пропусков в столбце с количеством недвижимости.\n",
    "Пробуем заполнить пропуски медианным значением количества недвижимости, как у людей такого же возраста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients['Tenure'] = clients['Tenure'].fillna(clients.groupby('Age')['Tenure'].transform('median'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             10000 non-null float64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "clients.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь все пропуски заполнены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_with_dummies = pd.get_dummies(clients, columns=['Gender', 'Geography'])\n",
    "# методом прямого кодирования переводим признаки пола и страны в численные, чтобы можно было анализировать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clients_with_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделяем исходные данные на обучающую, валидационную и тестовую выборки в соотношении 3:1:1 за два этапа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = clients_with_dummies['Exited'] \n",
    "features = clients_with_dummies.drop(columns=['Exited','RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "#Чтобы не мешать модели, удалим и столбцы, которые не несут нужной нам информации. \n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features, target, test_size=0.4, random_state=12345)\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_valid, target_valid, test_size=0.5, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "# выделяем столбцы с численными значениями признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() # проводим стандартизацию данных, т.к. имеем большой разброс значений для разных столбцов\n",
    "scaler.fit(features_train[numeric])\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "features_test[numeric] = scaler.transform(features_test[numeric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Исследование задачи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    7963\n",
      "1    2037\n",
      "Name: Exited, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(clients['Exited'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наблюдаем значительный дисбаланс классов: отношение ушедших клиентов к оставшимся 1:4.\n",
    "\n",
    "Для начала обучим модель без учёта дисбаланса.\n",
    "В качестве метрики будем использовать F1-меру. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 мера: 0.33389544688026984\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345, solver='liblinear') # будем исследовать модель логистической регрессии\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print('F-1 мера:', f1_score(target_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1 :0.0\n",
      "max_depth = 2 :0.5142576204523107\n",
      "max_depth = 3 :0.4157160963244613\n",
      "max_depth = 4 :0.5394456289978677\n",
      "max_depth = 5 :0.5579119086460032\n",
      "max_depth = 6 :0.596842105263158\n",
      "max_depth = 7 :0.6248693834900731\n",
      "max_depth = 8 :0.6473072861668427\n",
      "max_depth = 9 :0.7056530214424952\n",
      "max_depth = 10 :0.7427160493827161\n",
      "max_depth = 11 :0.7986921999065858\n",
      "max_depth = 12 :0.8446866485013624\n",
      "max_depth = 13 :0.8853932584269664\n",
      "max_depth = 14 :0.9176574196389256\n",
      "max_depth = 15 :0.9393139841688655\n",
      "max_depth = 16 :0.9589632829373651\n",
      "max_depth = 17 :0.9758781210325856\n",
      "max_depth = 18 :0.9847844463229077\n",
      "max_depth = 19 :0.9915895710681246\n",
      "{1: 0.0, 2: 0.5142576204523107, 3: 0.4157160963244613, 4: 0.5394456289978677, 5: 0.5579119086460032, 6: 0.596842105263158, 7: 0.6248693834900731, 8: 0.6473072861668427, 9: 0.7056530214424952, 10: 0.7427160493827161, 11: 0.7986921999065858, 12: 0.8446866485013624, 13: 0.8853932584269664, 14: 0.9176574196389256, 15: 0.9393139841688655, 16: 0.9589632829373651, 17: 0.9758781210325856, 18: 0.9847844463229077, 19: 0.9915895710681246}\n"
     ]
    }
   ],
   "source": [
    "# будем исследовать модель классификации деревом решений для разной максимальной глубины дерева\n",
    "\n",
    "model1_f1_train = {}\n",
    "for depth in range(1, 20): # проверяем модель на тренировочной выборке\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model.fit(features_train, target_train)\n",
    "    predicted_train = model.predict(features_train)\n",
    "    print('max_depth =', depth, ':', end='')\n",
    "    print(f1_score(target_train, predicted_train))\n",
    "    k1 = depth\n",
    "    model1_f1_train[k1] = f1_score(target_train, predicted_train) \n",
    "print(model1_f1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1 :0.0\n",
      "max_depth = 2 :0.5217391304347825\n",
      "max_depth = 3 :0.4234875444839857\n",
      "max_depth = 4 :0.5528700906344411\n",
      "max_depth = 5 :0.5406249999999999\n",
      "max_depth = 6 :0.5666666666666667\n",
      "max_depth = 7 :0.5462962962962963\n",
      "max_depth = 8 :0.5379939209726444\n",
      "max_depth = 9 :0.5610098176718092\n",
      "max_depth = 10 :0.5369318181818182\n",
      "max_depth = 11 :0.5284015852047557\n",
      "max_depth = 12 :0.5233160621761658\n",
      "max_depth = 13 :0.5077319587628866\n",
      "max_depth = 14 :0.5162907268170427\n",
      "max_depth = 15 :0.49811320754716976\n",
      "max_depth = 16 :0.4987654320987654\n",
      "max_depth = 17 :0.5006075334143378\n",
      "max_depth = 18 :0.4981949458483754\n",
      "max_depth = 19 :0.498220640569395\n"
     ]
    }
   ],
   "source": [
    "model1_f1_valid = {}\n",
    "for depth in range(1, 20): # проверяем модель классификации деревом решений на валидационной выборке\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model.fit(features_train, target_train)\n",
    "    predicted_valid = model.predict(features_valid)\n",
    "    print('max_depth =', depth, ':', end='')\n",
    "    print(f1_score(target_valid, predicted_valid)) \n",
    "    k2 = depth\n",
    "    model1_f1_valid[k2] = f1_score(target_valid, predicted_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'max depth')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1_f1_valid = pd.Series(model1_f1_valid)\n",
    "model1_f1_train = pd.Series(model1_f1_train)\n",
    "model1_f1 = pd.DataFrame({'model1_f1_valid': model1_f1_valid, 'model1_f1_train': model1_f1_train})\n",
    "#print(model1_acuracy)\n",
    "model1_f1.plot()\n",
    "plt.ylabel('F-1 мера')\n",
    "plt.xlabel('max depth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из графиков видим, что при глубине более 4 модель уже переобучается.\n",
    "Оптимальное значение глубины - 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 2 : 0.7732934728450425\n",
      "n_estimators = 12 : 0.9664371772805507\n",
      "n_estimators = 22 : 0.9894381073088298\n",
      "n_estimators = 32 : 0.9936895246108539\n",
      "n_estimators = 42 : 0.997485331098072\n",
      "n_estimators = 52 : 0.998324958123953\n",
      "n_estimators = 62 : 0.9987442444537463\n",
      "n_estimators = 72 : 0.999581764951903\n",
      "n_estimators = 82 : 0.999581764951903\n",
      "n_estimators = 92 : 0.999581764951903\n",
      "n_estimators = 102 : 0.999581764951903\n"
     ]
    }
   ],
   "source": [
    "# будем исследовать модель случайного леса для разного количества деревьев\n",
    "\n",
    "model2_f1_train = {}\n",
    "\n",
    "for estim in range(2, 103, 10): # проверяем модель на тренировочной выборке\n",
    "    model = RandomForestClassifier(n_estimators=estim, random_state=12345)\n",
    "    model.fit(features_train, target_train)\n",
    "    predicted_train = model.predict(features_train)\n",
    "    f1 = f1_score(target_train, predicted_train)\n",
    "    print(\"n_estimators =\", estim, \":\", f1)\n",
    "    k3 = estim\n",
    "    model2_f1_train[k3] = f1_score(target_train, predicted_train)\n",
    "#print(model2_f1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 2 : 0.36741214057507987\n",
      "n_estimators = 12 : 0.5432835820895522\n",
      "n_estimators = 22 : 0.5610859728506787\n",
      "n_estimators = 32 : 0.5636363636363636\n",
      "n_estimators = 42 : 0.5735735735735735\n",
      "n_estimators = 52 : 0.5696969696969697\n",
      "n_estimators = 62 : 0.5765765765765767\n",
      "n_estimators = 72 : 0.5697151424287856\n",
      "n_estimators = 82 : 0.5697151424287856\n",
      "n_estimators = 92 : 0.5718608169440242\n",
      "n_estimators = 102 : 0.5744680851063829\n"
     ]
    }
   ],
   "source": [
    "model2_f1_valid = {}\n",
    "\n",
    "for estim in range(2, 103, 10): # проверяем модель случайного леса на валидационной выборке\n",
    "    model = RandomForestClassifier(n_estimators=estim, random_state=12345)\n",
    "    model.fit(features_train, target_train)\n",
    "    predicted_valid = model.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, predicted_valid)\n",
    "    print(\"n_estimators =\", estim, \":\", f1)\n",
    "    k4 = estim\n",
    "    model2_f1_valid[k4] = f1_score(target_valid, predicted_valid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'n_estimators')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model2_f1_valid = pd.Series(model2_f1_valid)\n",
    "model2_f1_train = pd.Series(model2_f1_train)\n",
    "model2_f1 = pd.DataFrame({'model2_f1_valid': model2_f1_valid, 'model2_f1_train': model2_f1_train})\n",
    "\n",
    "model2_f1.plot()\n",
    "plt.ylabel('F1-мера')\n",
    "plt.xlabel('n_estimators')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность на тренировочной выборке выше, чем на валидационной - модель переобучена."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общий вывод:\n",
    "    при обучении модель без учёта дисбаланса тремя методами мы получили следующие результаты:\n",
    "    1. для модели логистической регресии F1-мера: 0.33\n",
    "    2. для модели случайного леса сразу происходит переобучение из-за дисбаланса, при избавлении от него будем использовать количество деревьев 10.\n",
    "    3. для модели классификации деревом решений получили максимальное значение F1-меры 0,55 для максимальной глубины 4. Это наилучший результат из трех моделей, но нам нужно его еще повысить. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Борьба с дисбалансом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Придадим объектам редкого класса больший вес (клиенты, которые расторгли договор)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5277777777777778\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=12345, max_depth=4, class_weight='balanced')\n",
    "# Если указать class_weight='balanced', больший вес будет у редкого класса\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print(f1_score(target_valid, predicted_valid)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1-мера даже снизилась до 0.528. Этот варинт не подходит для дерева решений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 мера: 0.4888507718696398\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345, solver='liblinear', class_weight='balanced') \n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print('F-1 мера:', f1_score(target_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для логистической регрессии F1-мера повысилась от 0.33 до 0.49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5381026438569206\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=10, random_state=12345, class_weight='balanced')\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "f1 = f1_score(target_valid, predicted_valid)\n",
    "print( f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для модели случайного леса результат ниже, чем для вариантов без учета классов,но должен быть точнее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(features, target, fraction): # используем downsampling, чтобы убрать часть неважных данных (20%, чтобы не терять много данных)\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "    \n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=12345)\n",
    "    \n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "features_downsampled, target_downsampled = downsample(features_train, target_train, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.5209003215434084\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=12345, max_depth=4) \n",
    "model.fit(features_downsampled, target_downsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print(\"F1:\", f1_score(target_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот варинт не подходит для дерева решений, эффекта нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 мера: 0.48805460750853236\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345, solver='liblinear', class_weight='balanced') \n",
    "model.fit(features_downsampled, target_downsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print('F-1 мера:', f1_score(target_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для логистической регресии ээфекта также нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 мера: 0.5387994143484627\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=10, random_state=12345, class_weight='balanced')\n",
    "model.fit(features_downsampled, target_downsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print('F-1 мера:', f1_score(target_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для модели стучайного леса также эффекта нет.\n",
    "Не будем учитывать это преобразование (с другими частями удаления также не работало, поэтому я и не включила эти преобразования в начальную версию работы)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat): #применяем метод upsampling для увеличения доли с 1\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle(\n",
    "        features_upsampled, target_upsampled, random_state=12345)\n",
    "    \n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.572987721691678\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=12345, max_depth=4) \n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print(\"F1:\", f1_score(target_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для дерева решений увеличение доли меньшего класса увеличивает F1-меру до 0.57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 мера: 0.4888507718696398\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345, solver='liblinear', class_weight='balanced') \n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print('F-1 мера:', f1_score(target_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для логистической регрессии даже немного уменьшил показатель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-1 мера: 0.5738636363636364\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=10, random_state=12345, class_weight='balanced')\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "print('F-1 мера:', f1_score(target_valid, predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пробуем подобрать оптимальное значение порога, чтобы увеличить F1-меру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Порог = 0.00 | F1-мера = 0.345 | auc-roc = 0.813\n",
      "Порог = 0.02 | F1-мера = 0.345 | auc-roc = 0.813\n",
      "Порог = 0.04 | F1-мера = 0.401 | auc-roc = 0.813\n",
      "Порог = 0.06 | F1-мера = 0.401 | auc-roc = 0.813\n",
      "Порог = 0.08 | F1-мера = 0.401 | auc-roc = 0.813\n",
      "Порог = 0.10 | F1-мера = 0.401 | auc-roc = 0.813\n",
      "Порог = 0.12 | F1-мера = 0.401 | auc-roc = 0.813\n",
      "Порог = 0.14 | F1-мера = 0.401 | auc-roc = 0.813\n",
      "Порог = 0.16 | F1-мера = 0.447 | auc-roc = 0.813\n",
      "Порог = 0.18 | F1-мера = 0.447 | auc-roc = 0.813\n",
      "Порог = 0.20 | F1-мера = 0.447 | auc-roc = 0.813\n",
      "Порог = 0.22 | F1-мера = 0.447 | auc-roc = 0.813\n",
      "Порог = 0.24 | F1-мера = 0.531 | auc-roc = 0.813\n",
      "Порог = 0.26 | F1-мера = 0.531 | auc-roc = 0.813\n",
      "Порог = 0.28 | F1-мера = 0.531 | auc-roc = 0.813\n",
      "Порог = 0.30 | F1-мера = 0.549 | auc-roc = 0.813\n",
      "Порог = 0.32 | F1-мера = 0.549 | auc-roc = 0.813\n",
      "Порог = 0.34 | F1-мера = 0.549 | auc-roc = 0.813\n",
      "Порог = 0.36 | F1-мера = 0.549 | auc-roc = 0.813\n",
      "Порог = 0.38 | F1-мера = 0.549 | auc-roc = 0.813\n",
      "Порог = 0.40 | F1-мера = 0.549 | auc-roc = 0.813\n",
      "Порог = 0.42 | F1-мера = 0.561 | auc-roc = 0.813\n",
      "Порог = 0.44 | F1-мера = 0.561 | auc-roc = 0.813\n",
      "Порог = 0.46 | F1-мера = 0.561 | auc-roc = 0.813\n",
      "Порог = 0.48 | F1-мера = 0.573 | auc-roc = 0.813\n",
      "Порог = 0.50 | F1-мера = 0.573 | auc-roc = 0.813\n",
      "Порог = 0.52 | F1-мера = 0.573 | auc-roc = 0.813\n",
      "Порог = 0.54 | F1-мера = 0.573 | auc-roc = 0.813\n",
      "Порог = 0.56 | F1-мера = 0.573 | auc-roc = 0.813\n",
      "Порог = 0.58 | F1-мера = 0.553 | auc-roc = 0.813\n",
      "Порог = 0.60 | F1-мера = 0.553 | auc-roc = 0.813\n",
      "Порог = 0.62 | F1-мера = 0.553 | auc-roc = 0.813\n",
      "Порог = 0.64 | F1-мера = 0.553 | auc-roc = 0.813\n",
      "Порог = 0.66 | F1-мера = 0.553 | auc-roc = 0.813\n",
      "Порог = 0.68 | F1-мера = 0.553 | auc-roc = 0.813\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(random_state=12345, max_depth=4) \n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "for threshold in np.arange(0, 0.7, 0.02):\n",
    "    predicted_valid = probabilities_one_valid > threshold\n",
    "    f1 = f1_score(target_valid, predicted_valid)\n",
    "    auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    print(\"Порог = {:.2f} | F1-мера = {:.3f} | auc-roc = {:.3f}\".format(threshold, f1, auc_roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Порог = 0.00 | F1-мера = 0.346 | auc-roc = 0.764\n",
      "Порог = 0.02 | F1-мера = 0.346 | auc-roc = 0.764\n",
      "Порог = 0.04 | F1-мера = 0.346 | auc-roc = 0.764\n",
      "Порог = 0.06 | F1-мера = 0.347 | auc-roc = 0.764\n",
      "Порог = 0.08 | F1-мера = 0.349 | auc-roc = 0.764\n",
      "Порог = 0.10 | F1-мера = 0.354 | auc-roc = 0.764\n",
      "Порог = 0.12 | F1-мера = 0.359 | auc-roc = 0.764\n",
      "Порог = 0.14 | F1-мера = 0.368 | auc-roc = 0.764\n",
      "Порог = 0.16 | F1-мера = 0.375 | auc-roc = 0.764\n",
      "Порог = 0.18 | F1-мера = 0.380 | auc-roc = 0.764\n",
      "Порог = 0.20 | F1-мера = 0.387 | auc-roc = 0.764\n",
      "Порог = 0.22 | F1-мера = 0.398 | auc-roc = 0.764\n",
      "Порог = 0.24 | F1-мера = 0.402 | auc-roc = 0.764\n",
      "Порог = 0.26 | F1-мера = 0.407 | auc-roc = 0.764\n",
      "Порог = 0.28 | F1-мера = 0.415 | auc-roc = 0.764\n",
      "Порог = 0.30 | F1-мера = 0.424 | auc-roc = 0.764\n",
      "Порог = 0.32 | F1-мера = 0.431 | auc-roc = 0.764\n",
      "Порог = 0.34 | F1-мера = 0.440 | auc-roc = 0.764\n",
      "Порог = 0.36 | F1-мера = 0.451 | auc-roc = 0.764\n",
      "Порог = 0.38 | F1-мера = 0.464 | auc-roc = 0.764\n",
      "Порог = 0.40 | F1-мера = 0.472 | auc-roc = 0.764\n",
      "Порог = 0.42 | F1-мера = 0.475 | auc-roc = 0.764\n",
      "Порог = 0.44 | F1-мера = 0.487 | auc-roc = 0.764\n",
      "Порог = 0.46 | F1-мера = 0.485 | auc-roc = 0.764\n",
      "Порог = 0.48 | F1-мера = 0.486 | auc-roc = 0.764\n",
      "Порог = 0.50 | F1-мера = 0.489 | auc-roc = 0.764\n",
      "Порог = 0.52 | F1-мера = 0.494 | auc-roc = 0.764\n",
      "Порог = 0.54 | F1-мера = 0.499 | auc-roc = 0.764\n",
      "Порог = 0.56 | F1-мера = 0.496 | auc-roc = 0.764\n",
      "Порог = 0.58 | F1-мера = 0.495 | auc-roc = 0.764\n",
      "Порог = 0.60 | F1-мера = 0.491 | auc-roc = 0.764\n",
      "Порог = 0.62 | F1-мера = 0.501 | auc-roc = 0.764\n",
      "Порог = 0.64 | F1-мера = 0.488 | auc-roc = 0.764\n",
      "Порог = 0.66 | F1-мера = 0.475 | auc-roc = 0.764\n",
      "Порог = 0.68 | F1-мера = 0.457 | auc-roc = 0.764\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345, solver='liblinear', class_weight='balanced') \n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "for threshold in np.arange(0, 0.7, 0.02):\n",
    "    predicted_valid = probabilities_one_valid > threshold\n",
    "    f1 = f1_score(target_valid, predicted_valid)\n",
    "    auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    print(\"Порог = {:.2f} | F1-мера = {:.3f} | auc-roc = {:.3f}\".format(threshold, f1, auc_roc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Порог = 0.00 | F1-мера = 0.427 | auc-roc = 0.814\n",
      "Порог = 0.02 | F1-мера = 0.427 | auc-roc = 0.814\n",
      "Порог = 0.04 | F1-мера = 0.427 | auc-roc = 0.814\n",
      "Порог = 0.06 | F1-мера = 0.427 | auc-roc = 0.814\n",
      "Порог = 0.08 | F1-мера = 0.427 | auc-roc = 0.814\n",
      "Порог = 0.10 | F1-мера = 0.491 | auc-roc = 0.814\n",
      "Порог = 0.12 | F1-мера = 0.491 | auc-roc = 0.814\n",
      "Порог = 0.14 | F1-мера = 0.491 | auc-roc = 0.814\n",
      "Порог = 0.16 | F1-мера = 0.491 | auc-roc = 0.814\n",
      "Порог = 0.18 | F1-мера = 0.491 | auc-roc = 0.814\n",
      "Порог = 0.20 | F1-мера = 0.542 | auc-roc = 0.814\n",
      "Порог = 0.22 | F1-мера = 0.542 | auc-roc = 0.814\n",
      "Порог = 0.24 | F1-мера = 0.542 | auc-roc = 0.814\n",
      "Порог = 0.26 | F1-мера = 0.542 | auc-roc = 0.814\n",
      "Порог = 0.28 | F1-мера = 0.542 | auc-roc = 0.814\n",
      "Порог = 0.30 | F1-мера = 0.577 | auc-roc = 0.814\n",
      "Порог = 0.32 | F1-мера = 0.577 | auc-roc = 0.814\n",
      "Порог = 0.34 | F1-мера = 0.577 | auc-roc = 0.814\n",
      "Порог = 0.36 | F1-мера = 0.577 | auc-roc = 0.814\n",
      "Порог = 0.38 | F1-мера = 0.577 | auc-roc = 0.814\n",
      "Порог = 0.40 | F1-мера = 0.591 | auc-roc = 0.814\n",
      "Порог = 0.42 | F1-мера = 0.591 | auc-roc = 0.814\n",
      "Порог = 0.44 | F1-мера = 0.591 | auc-roc = 0.814\n",
      "Порог = 0.46 | F1-мера = 0.591 | auc-roc = 0.814\n",
      "Порог = 0.48 | F1-мера = 0.591 | auc-roc = 0.814\n",
      "Порог = 0.50 | F1-мера = 0.574 | auc-roc = 0.814\n",
      "Порог = 0.52 | F1-мера = 0.574 | auc-roc = 0.814\n",
      "Порог = 0.54 | F1-мера = 0.574 | auc-roc = 0.814\n",
      "Порог = 0.56 | F1-мера = 0.574 | auc-roc = 0.814\n",
      "Порог = 0.58 | F1-мера = 0.574 | auc-roc = 0.814\n",
      "Порог = 0.60 | F1-мера = 0.511 | auc-roc = 0.814\n",
      "Порог = 0.62 | F1-мера = 0.511 | auc-roc = 0.814\n",
      "Порог = 0.64 | F1-мера = 0.511 | auc-roc = 0.814\n",
      "Порог = 0.66 | F1-мера = 0.511 | auc-roc = 0.814\n",
      "Порог = 0.68 | F1-мера = 0.511 | auc-roc = 0.814\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=10, random_state=12345, class_weight='balanced')\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "for threshold in np.arange(0, 0.7, 0.02):\n",
    "    predicted_valid = probabilities_one_valid > threshold\n",
    "    f1 = f1_score(target_valid, predicted_valid)\n",
    "    auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    print(\"Порог = {:.2f} | F1-мера = {:.3f} | auc-roc = {:.3f}\".format(threshold, f1, auc_roc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Общий вывод по изменению порогов:\n",
    " На дерево решений и логистическую регрессию изменение порогов не позволило нам дотянуть до нужного нам показателя.\n",
    " А для модели случайного леса такой порог мы нашли - 0.4 с соответствующим значенем F1-меры 0.591 (значение auc-roc = 0.814 - постоянное для любых порогов и больше, чем в случае с другими моделями).\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера 0.5911330049261084 auc_roc 0.7384087733412372\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=10, random_state=12345, class_weight='balanced') # используем найденный нами порог\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "probabilities_one_valid_threshold = np.where(probabilities_one_valid > 0.4, 1, 0)\n",
    "predicted_valid = probabilities_one_valid_threshold\n",
    "f1 = f1_score(target_valid, predicted_valid)\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid_threshold)\n",
    "print('F1-мера', f1, 'auc_roc', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Тестирование модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-мера 0.5591133004926109 auc_roc 0.4889592242875894\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=10, random_state=12345, class_weight='balanced')\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "probabilities_test = model.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "probabilities_one_test_threshold = np.where(probabilities_one_test > 0.4, 1, 0)\n",
    "predicted_test = probabilities_one_test_threshold\n",
    "f1 = f1_score(target_test, predicted_test)\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_test_threshold)\n",
    "print('F1-мера', f1, 'auc_roc', auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Общий вывод\n",
    "\n",
    "При работе с данными со значительным дисбалансом классов качество работы моделей может сильно отличатся от вариантов, когда дисбаланс классов максимально нивелирован.\n",
    "\n",
    "При улучшении качества моделей при дисбалансе классов разные инструменты работают по разному как для датасета, так и для разных моделей, поэтому нужво проверять разные варианты.\n",
    "\n",
    "При использовании разных способов мы выбрали лучшую модель - модели случайного леса (кол-во деревьев 10 с порогом 0.4). Она продемострировала нужное нам значение F1-меры 0.591 (значение auc-roc = 0.814 - постоянное для любых порогов и больше, чем в случае с другими моделями).\n",
    "\n",
    "К сожалению, на тестовой модели результат оказался ниже:\n",
    "   - F1-мера=0.559 и auc_roc=0.489."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
